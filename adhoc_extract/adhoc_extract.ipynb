{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package imports & Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from configparser import ConfigParser\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from src import project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Prajwal.G\\\\Documents\\\\POC\\\\techdocInjestion\\\\config\\\\config.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_FOLDER = os.path.join(project_root,'config')\n",
    "CONFIG_FILE = os.path.join(CONFIG_FOLDER,'config.ini')\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference File \n",
    "Base excel containing list of OEM and IAM skus to be queried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the loaded dataframe (86425, 2)\n",
      "\n",
      "Distribution of item ids: \n",
      "Brand\n",
      "OEM    67574\n",
      "IAM    18851\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QY000003</td>\n",
       "      <td>OEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QY010016</td>\n",
       "      <td>OEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08790-3M000A</td>\n",
       "      <td>OEM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SKU Brand\n",
       "0      QY000003   OEM\n",
       "1      QY010016   OEM\n",
       "2  08790-3M000A   OEM"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oem_iam_df = pd.read_excel('adhoc_extract/OEM-IAM.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "print(f\"Shape of the loaded dataframe {oem_iam_df.shape}\\n\")\n",
    "print(f\"Distribution of item ids: \\n{oem_iam_df['Brand'].value_counts()}\")\n",
    "\n",
    "oem_iam_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDFs\n",
    "API calls, parallel processing, persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_payload(searchType, includeAll='false',includeImages='false',includeGenericArticles='true',includeOEMNumbers='true' ) -> dict:\n",
    "    \"\"\"\n",
    "    Creates payload dict object based on search type\n",
    "    1: Input Query is an OEM Brand\n",
    "    0: Input Query is an IAM Brand\n",
    "    99: Get based on partial match\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"getArticles\": {\n",
    "            \"articleCountry\": \"AE\",\n",
    "            \"provider\": \"22610\",\n",
    "            \"searchQuery\": \"\",\n",
    "            \"searchType\": searchType,\n",
    "            \"lang\": \"en\",\n",
    "            \"perPage\": 100,\n",
    "            \"page\": 1,\n",
    "            \"includeAll\": includeAll,\n",
    "            \"imcludeImages\": includeImages,\n",
    "            \"includeGenericArticles\": includeGenericArticles,\n",
    "            \"includeOEMNumbers\": includeOEMNumbers\n",
    "        }\n",
    "    }\n",
    "\n",
    "def json_to_df(response_json):\n",
    "    \"\"\"\n",
    "    Converts json objects into pandas dataframe\n",
    "    \"\"\"\n",
    "    # Flattening the genericArticles\n",
    "    df_generic_articles = pd.json_normalize(\n",
    "        response_json,\n",
    "        record_path='genericArticles',\n",
    "        meta=['dataSupplierId', 'articleNumber', 'mfrId', 'mfrName', 'searchQuery'],\n",
    "        record_prefix='genericArticle_',\n",
    "        errors='ignore'\n",
    "    )\n",
    "\n",
    "    # Flattening the oemNumbers\n",
    "    df_oem_numbers = pd.json_normalize(\n",
    "        response_json,\n",
    "        record_path='oemNumbers',\n",
    "        meta=['dataSupplierId', 'articleNumber', 'mfrId', 'mfrName', 'searchQuery'],\n",
    "        record_prefix='oem_',\n",
    "        errors='ignore'\n",
    "    )\n",
    "\n",
    "    # Merging the two dataframes on common columns\n",
    "    df_merged = pd.merge(df_generic_articles, df_oem_numbers, on=['dataSupplierId', 'articleNumber', 'mfrId', 'mfrName', 'searchQuery'], how='outer')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def query_oem(oem, url, payload, params):\n",
    "    oemQuery = oem\n",
    "    s = requests.Session()\n",
    "    response_list = []\n",
    "    no_response_list = []\n",
    "    problem_items_list = []\n",
    "    counter = 0\n",
    "    page = 1\n",
    "    while True:\n",
    "        try:\n",
    "            with s as session:\n",
    "                payload['getArticles']['searchQuery'] = oemQuery\n",
    "                payload['getArticles']['page'] = page\n",
    "                response = session.post(url=url, params=params, json=payload)\n",
    "                try:\n",
    "                    if response.status_code == 200 and len(response.json()['articles']) > 0:\n",
    "                        response_json = response.json()['articles']\n",
    "                        for item in response_json: item['searchQuery'] = oemQuery\n",
    "                        response_list.append(response_json)\n",
    "                        counter += len(response_json)\n",
    "                        page += 1\n",
    "                    elif response.status_code == 200 and len(response.json()['articles']) == 0:\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Error {response.status_code}: {response.text}\")\n",
    "                        if page == 1:\n",
    "                            problem_items_list = [\n",
    "                                [\n",
    "                                    {\n",
    "                                        'searchQuery':oem, \n",
    "                                        'Status Code':response.status_code,\n",
    "                                        'Error': response.text\n",
    "                                    }\n",
    "                                ]\n",
    "                            ]\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    break\n",
    "        except requests.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                break\n",
    "        \n",
    "    if len(response_list) > 0:\n",
    "        response_list = list(map(lambda x: json_to_df(x), response_list))\n",
    "    elif len(response_list) == 0:\n",
    "        no_response_list = [[{'searchQuery':oem}]]\n",
    "        no_response_list = list(map(lambda x: pd.json_normalize(x), no_response_list))\n",
    "    elif len(problem_items_list) > 0:\n",
    "        problem_items_list= list(map(lambda x: pd.json_normalize(x), problem_items_list))\n",
    "        \n",
    "    return response_list, no_response_list, problem_items_list\n",
    "\n",
    "def process_batch(batch, url, params, payload):\n",
    "    response_list, no_response_list, problem_items_list = [], [], []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_sku = {executor.submit(query_oem, oem, url, payload, params): oem for oem in batch}\n",
    "        for future in as_completed(future_to_sku):\n",
    "            response, no_response, problem_items = future.result()\n",
    "            response_list.extend(response)\n",
    "            no_response_list.extend(no_response)\n",
    "            problem_items_list.extend(problem_items)\n",
    "    return response_list, no_response_list, problem_items\n",
    "\n",
    "def save_data_in_batches(articles, no_response_list, problem_items, index, data_stage_location):\n",
    "    try:\n",
    "        if not articles.empty:\n",
    "            save_to_csv(articles, \"oem_matches\", index, data_stage_location)\n",
    "        if not no_response_list.empty:\n",
    "            save_to_csv(no_response_list, \"no_responses\", index, data_stage_location)\n",
    "        if not problem_items.empty:\n",
    "            save_to_csv(problem_items, \"errors\", index, data_stage_location)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred during saving CSV: {e}\")\n",
    "\n",
    "def save_to_csv(df, file_type, index, data_stage_location):\n",
    "    start, end = max(0, index - 5000), index\n",
    "    dt_stamp = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_path = os.path.join(data_stage_location,file_type,f\"{file_type}_{start}_{end}_{dt_stamp}.csv\")\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispatching elements between index 0 to 5000\n",
      "Dispatching elements between index 5000 to 10000\n",
      "Dispatching elements between index 10000 to 15000\n",
      "Dispatching elements between index 15000 to 20000\n",
      "Dispatching elements between index 20000 to 25000\n",
      "Dispatching elements between index 25000 to 30000\n",
      "Dispatching elements between index 30000 to 35000\n",
      "Dispatching elements between index 35000 to 40000\n",
      "Dispatching elements between index 40000 to 45000\n",
      "Dispatching elements between index 45000 to 50000\n",
      "Dispatching elements between index 50000 to 55000\n",
      "Dispatching elements between index 55000 to 60000\n",
      "Dispatching elements between index 60000 to 65000\n",
      "Dispatching elements between index 65000 to 70000\n",
      "Extraction completed successfully\n"
     ]
    }
   ],
   "source": [
    "oem_list = oem_iam_df[oem_iam_df['Brand'] == 'OEM']['SKU']\n",
    "batch_size = 5000\n",
    "\n",
    "payload = create_payload(searchType=1)\n",
    "params = params = {'api_key': config['techdoc']['api_key']}\n",
    "url = 'https://webservice.tecalliance.services/pegasus-3-0/services/TecdocToCatDLB.jsonEndpoint'\n",
    "\n",
    "for start in range(0, len(oem_list), batch_size):\n",
    "    end = start + batch_size\n",
    "    print(f\"Dispatching elements between index {start} to {end}\")\n",
    "    batch = oem_list[start:end]\n",
    "    response_list, no_response_list, problem_items_list = process_batch(batch=batch, url=url, params=params, payload=payload)\n",
    "    \n",
    "    # Handling the outputs\n",
    "    response_df = pd.DataFrame()\n",
    "    no_response_df = pd.DataFrame()\n",
    "    problem_items_df = pd.DataFrame()\n",
    "\n",
    "    if len(response_list) > 0:\n",
    "        response_df = pd.concat(response_list).reset_index(drop=True)\n",
    "\n",
    "    if len(no_response_list) > 0:\n",
    "        no_response_df = pd.concat(no_response_list).reset_index(drop=True)\n",
    "\n",
    "    if len(problem_items_list) > 0:\n",
    "        problem_items_df = pd.concat(problem_items_list).reset_index(drop=True)\n",
    "    \n",
    "    save_data_in_batches(response_df, no_response_df, problem_items_df, end, 'adhoc_extract/custom_data_extract/oem')\n",
    "        \n",
    "print(\"Extraction completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of uniques items with match: 25476\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'oem_matches'\n",
    "path = f'adhoc_extract/custom_data_extract/oem/{folder_name}'\n",
    "contents = os.listdir(path)\n",
    "oem_match_df = []\n",
    "\n",
    "for each in contents:\n",
    "    if each.endswith('.csv'):\n",
    "        file_path = f\"{os.path.join(path,each)}\"\n",
    "        oem_match_df.append(pd.read_csv(file_path))\n",
    "\n",
    "oem_match_df = pd.concat(oem_match_df, axis=0)\n",
    "\n",
    "print(f\"Total number of uniques items with match: {oem_match_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of uniques items with match: 42098\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'no_responses'\n",
    "path = f'adhoc_extract/custom_data_extract/oem/{folder_name}'\n",
    "contents = os.listdir(path)\n",
    "oem_no_match_df = []\n",
    "\n",
    "for each in contents:\n",
    "    if each.endswith('.csv'):\n",
    "        file_path = f\"{os.path.join(path,each)}\"\n",
    "        oem_no_match_df.append(pd.read_csv(file_path))\n",
    "\n",
    "oem_no_match_df = pd.concat(oem_no_match_df, axis=0)\n",
    "\n",
    "print(f\"Total number of uniques items with match: {oem_no_match_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Items Have Been Accounted for\n",
      "Total Number of OEM Parts accounted for 67574\n"
     ]
    }
   ],
   "source": [
    "if oem_match_df['searchQuery'].nunique() + oem_no_match_df['searchQuery'].nunique() == len(oem_list):\n",
    "    print(\"All Items Have Been Accounted for\")\n",
    "    oem_main_df = pd.concat([oem_match_df,oem_no_match_df], axis=0)\n",
    "    print(f\"Total Number of OEM Parts accounted for {oem_main_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oem_main_df.to_csv('adhoc_extract/custom_data_extract/oems.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispatching elements between index 0 to 5000\n",
      "Dispatching elements between index 5000 to 10000\n",
      "Dispatching elements between index 10000 to 15000\n",
      "Dispatching elements between index 15000 to 20000\n",
      "Extraction completed successfully\n"
     ]
    }
   ],
   "source": [
    "iam_list = oem_iam_df[oem_iam_df['Brand'] == 'IAM']['SKU']\n",
    "batch_size = 5000\n",
    "\n",
    "payload = create_payload(searchType=0)\n",
    "params = params = {'api_key': config['techdoc']['api_key']}\n",
    "url = 'https://webservice.tecalliance.services/pegasus-3-0/services/TecdocToCatDLB.jsonEndpoint'\n",
    "\n",
    "for start in range(0, len(iam_list), batch_size):\n",
    "    end = start + batch_size\n",
    "    print(f\"Dispatching elements between index {start} to {end}\")\n",
    "    batch = iam_list[start:end]\n",
    "    response_list, no_response_list, problem_items_list = process_batch(batch=batch, url=url, params=params, payload=payload)\n",
    "    \n",
    "    # Handling the outputs\n",
    "    response_df = pd.DataFrame()\n",
    "    no_response_df = pd.DataFrame()\n",
    "    problem_items_df = pd.DataFrame()\n",
    "\n",
    "    if len(response_list) > 0:\n",
    "        response_df = pd.concat(response_list).reset_index(drop=True)\n",
    "\n",
    "    if len(no_response_list) > 0:\n",
    "        no_response_df = pd.concat(no_response_list).reset_index(drop=True)\n",
    "\n",
    "    if len(problem_items_list) > 0:\n",
    "        problem_items_df = pd.concat(problem_items_list).reset_index(drop=True)\n",
    "    \n",
    "    save_data_in_batches(response_df, no_response_df, problem_items_df, end, 'adhoc_extract/custom_data_extract/iam')\n",
    "        \n",
    "print(\"Extraction completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of uniques items with match: 13369\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'oem_matches'\n",
    "path = f'adhoc_extract/custom_data_extract/iam/{folder_name}'\n",
    "contents = os.listdir(path)\n",
    "iam_match_df = []\n",
    "\n",
    "for each in contents:\n",
    "    if each.endswith('.csv'):\n",
    "        file_path = f\"{os.path.join(path,each)}\"\n",
    "        iam_match_df.append(pd.read_csv(file_path))\n",
    "\n",
    "iam_match_df = pd.concat(iam_match_df, axis=0)\n",
    "\n",
    "print(f\"Total number of uniques items with match: {iam_match_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of uniques items with match: 5482\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'no_responses'\n",
    "path = f'adhoc_extract/custom_data_extract/iam/{folder_name}'\n",
    "contents = os.listdir(path)\n",
    "iam_no_match_df = []\n",
    "\n",
    "for each in contents:\n",
    "    if each.endswith('.csv'):\n",
    "        file_path = f\"{os.path.join(path,each)}\"\n",
    "        iam_no_match_df.append(pd.read_csv(file_path))\n",
    "\n",
    "iam_no_match_df = pd.concat(iam_no_match_df, axis=0)\n",
    "\n",
    "print(f\"Total number of uniques items with match: {iam_no_match_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Items Have Been Accounted for\n",
      "Total Number of OEM Parts accounted for 18851\n"
     ]
    }
   ],
   "source": [
    "if iam_match_df['searchQuery'].nunique() + iam_no_match_df['searchQuery'].nunique() == len(iam_list):\n",
    "    print(\"All Items Have Been Accounted for\")\n",
    "    iam_main_df = pd.concat([iam_match_df,iam_no_match_df], axis=0)\n",
    "    print(f\"Total Number of OEM Parts accounted for {iam_main_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_main_df.to_csv('adhoc_extract/custom_data_extract/iams.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sku_list = oem_iam_df['SKU']\n",
    "batch_size = 1000\n",
    "\n",
    "payload = create_payload(searchType=99)\n",
    "params = params = {'api_key': config['techdoc']['api_key']}\n",
    "url = 'https://webservice.tecalliance.services/pegasus-3-0/services/TecdocToCatDLB.jsonEndpoint'\n",
    "\n",
    "for start in range(0, len(all_sku_list), batch_size):\n",
    "    end = start + batch_size\n",
    "    print(f\"Dispatching elements between index {start} to {end}\")\n",
    "    batch = all_sku_list[start:end]\n",
    "    response_list, no_response_list, problem_items_list = process_batch(batch=batch, url=url, params=params, payload=payload)\n",
    "    \n",
    "    # Handling the outputs\n",
    "    response_df = pd.DataFrame()\n",
    "    no_response_df = pd.DataFrame()\n",
    "    problem_items_df = pd.DataFrame()\n",
    "\n",
    "    if len(response_list) > 0:\n",
    "        response_df = pd.concat(response_list).reset_index(drop=True)\n",
    "\n",
    "    if len(no_response_list) > 0:\n",
    "        no_response_df = pd.concat(no_response_list).reset_index(drop=True)\n",
    "\n",
    "    if len(problem_items_list) > 0:\n",
    "        problem_items_df = pd.concat(problem_items_list).reset_index(drop=True)\n",
    "    \n",
    "    save_data_in_batches(response_df, no_response_df, problem_items_df, end, 'custom_data_extract/all')\n",
    "        \n",
    "print(\"Extraction completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'oem_matches'\n",
    "path = f'C:\\\\Users\\\\Prajwal.G\\\\Documents\\\\POC\\\\techdocInjestion\\\\custom_data_extract\\\\all\\\\{folder_name}'\n",
    "contents = os.listdir(path)\n",
    "all_match_df = []\n",
    "\n",
    "for each in contents:\n",
    "    if each.endswith('.csv'):\n",
    "        file_path = f\"{os.path.join(path,each)}\"\n",
    "        all_match_df.append(pd.read_csv(file_path))\n",
    "\n",
    "all_match_df = pd.concat(all_match_df, axis=0)\n",
    "\n",
    "print(f\"Total number of uniques items with match: {all_match_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of uniques items with match: 44407\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'no_responses'\n",
    "path = f'C:\\\\Users\\\\Prajwal.G\\\\Documents\\\\POC\\\\techdocInjestion\\\\custom_data_extract\\\\all\\\\{folder_name}'\n",
    "contents = os.listdir(path)\n",
    "all_no_match_df = []\n",
    "\n",
    "for each in contents:\n",
    "    if each.endswith('.csv'):\n",
    "        file_path = f\"{os.path.join(path,each)}\"\n",
    "        all_no_match_df.append(pd.read_csv(file_path))\n",
    "\n",
    "all_no_match_df = pd.concat(all_no_match_df, axis=0)\n",
    "\n",
    "print(f\"Total number of uniques items with match: {all_no_match_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_match_df['searchQuery'].nunique() + all_no_match_df['searchQuery'].nunique() == len(all_sku_list):\n",
    "    print(\"All Items Have Been Accounted for\")\n",
    "    main_df = pd.concat([all_match_df,all_no_match_df], axis=0)\n",
    "    print(f\"Total Number of OEM Parts accounted for {main_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of OEM Parts accounted for 86427\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.concat([all_match_df,all_no_match_df], axis=0)\n",
    "print(f\"Total Number of OEM Parts accounted for {main_df['searchQuery'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv('all.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techdocenv",
   "language": "python",
   "name": "techdocenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
